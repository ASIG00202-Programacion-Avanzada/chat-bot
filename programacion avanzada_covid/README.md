# ğŸš€ Pipeline COVID-19 Argentina con Papermill

**Pipeline automatizado que cumple con los requisitos de la tarea:**
- âœ… Descarga datos pÃºblicos de COVID-19 de Argentina
- âœ… Aplica transformaciones bÃ¡sicas
- âœ… Ejecuta runs parametrizados con Papermill
- âœ… Genera reporte final con los resultados

## ğŸ“‹ Requisitos

- Python 3.7+
- Dependencias: `pip install -r requirements.txt`

## ğŸš€ Uso RÃ¡pido

```bash
# OpciÃ³n 1: Ejecutar todo automÃ¡ticamente
python test_pipeline.py

# OpciÃ³n 2: Ejecutar paso a paso
python scripts/download_and_prep.py
python run_papermill_pipeline.py
```

## ğŸ“ Estructura del Proyecto

```
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ template_notebook.ipynb    # Notebook parametrizado para Papermill
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ download_and_prep.py       # Descarga datos de Johns Hopkins
â”‚   â””â”€â”€ clean_artifacts.py         # Limpieza de archivos generados
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ report_template.html       # Template del reporte final
â”œâ”€â”€ data/                          # Datos descargados (CSV de Argentina)
â”œâ”€â”€ output/                        # Resultados: imÃ¡genes y JSON
â”œâ”€â”€ executed/                      # Notebooks ejecutados por Papermill
â”œâ”€â”€ run_papermill_pipeline.py      # Pipeline principal con Papermill
â”œâ”€â”€ test_pipeline.py              # Script de pruebas
â””â”€â”€ report.html                   # Reporte final generado
```

## ğŸ”§ Archivos Clave

- **`run_papermill_pipeline.py`**: Pipeline principal que usa Papermill para ejecutar notebooks parametrizados
- **`notebooks/template_notebook.ipynb`**: Notebook template con parÃ¡metros para Argentina
- **`templates/report_template.html`**: Template HTML profesional para el reporte final
- **`scripts/download_and_prep.py`**: Descarga y prepara datos de Argentina de Johns Hopkins CSSE

## ğŸ“Š CaracterÃ­sticas del Pipeline

### 1. **Descarga AutomÃ¡tica de Datos**
- Descarga datos de COVID-19 desde Johns Hopkins CSSE
- Procesa datos de Argentina
- Genera archivos CSV especÃ­ficos

### 2. **Procesamiento Parametrizado con Papermill**
- Ejecuta notebook template para Argentina
- ParÃ¡metros: nombre del paÃ­s
- Manejo de errores robusto

### 3. **Transformaciones de Datos**
- CÃ¡lculo de nuevos casos diarios
- Media mÃ³vil de 7 dÃ­as
- EstadÃ­sticas descriptivas

### 4. **Visualizaciones AutomÃ¡ticas**
- GrÃ¡ficos de casos acumulados
- GrÃ¡ficos de nuevos casos diarios con media mÃ³vil
- ImÃ¡genes de alta calidad (300 DPI)

### 5. **Reporte Final Profesional**
- Dashboard HTML responsivo
- EstadÃ­sticas resumidas
- Visualizaciones integradas
- Manejo de errores en el reporte

## ğŸ§ª Pruebas

```bash
# Ejecutar pruebas completas
python test_pipeline.py

# Verificar dependencias
pip install -r requirements.txt

# Limpiar archivos generados
python scripts/clean_artifacts.py
```

## ğŸ“ˆ Resultados

El pipeline genera:
- **`report.html`**: Reporte final con todas las provincias
- **`output/`**: ImÃ¡genes PNG y archivos JSON por provincia
- **`executed/`**: Notebooks ejecutados por Papermill
- **Consola**: Log detallado del procesamiento

## ğŸ” Monitoreo

El pipeline muestra progreso en tiempo real:
- âœ… Provincias procesadas exitosamente
- âŒ Provincias con errores
- ğŸ“Š EstadÃ­sticas resumidas
- ğŸ“ Archivos generados

INTRODUCCIÃ“N

Tu equipo necesita un flujo reproducible que genere indicadores diarios de un dataset. Deciden usar notebooks automatizados con Papermill para facilitar la ejecuciÃ³n con distintos parÃ¡metros. Tu misiÃ³n es construir un pipeline que ejecute notebooks parametrizados para distintas provincias argentinas y compile un reporte final.

OBJETIVO

Automatizar con Papermill la ejecuciÃ³n de un pipeline de notebooks que:

- Descargue datos pÃºblicos
- Aplique transformaciones bÃ¡sicas
- Ejecute mÃºltiples runs parametrizados
- Genere un reporte final con los resultados

Limpieza de artefactos:
- Los resultados generados (imÃ¡genes, JSON y notebooks ejecutados) se guardan en `output/` y `executed/`. Para limpiarlos puede usar `scripts/clean_artifacts.py`.

Notas:
- Si borras los datos en `data/`, puedes regenerarlos con `python scripts/download_and_prep.py`.

```shell
# Ejemplo rÃ¡pido:
python scripts/download_and_prep.py
python run_pipeline.py
```